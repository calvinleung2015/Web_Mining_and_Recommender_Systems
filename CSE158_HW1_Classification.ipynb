{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review/appearance': 4.0,\n",
       " 'beer/style': 'Rauchbier',\n",
       " 'review/palate': 3.5,\n",
       " 'review/taste': 3.5,\n",
       " 'beer/name': 'Rauch Ã\\x9cr Bock',\n",
       " 'review/timeUnix': 1297290394,\n",
       " 'beer/ABV': 7.4,\n",
       " 'beer/beerId': '58046',\n",
       " 'beer/brewerId': '1075',\n",
       " 'review/timeStruct': {'isdst': 0,\n",
       "  'mday': 9,\n",
       "  'hour': 22,\n",
       "  'min': 26,\n",
       "  'sec': 34,\n",
       "  'mon': 2,\n",
       "  'year': 2011,\n",
       "  'yday': 40,\n",
       "  'wday': 2},\n",
       " 'review/overall': 3.5,\n",
       " 'review/text': \"Got this in a 22 ounce bomber. It poured a deep bright brown with a pretty small head. \\t\\tAromas of smoked kielba, and dark roasted malts. \\t\\tThis beer was OK but for a style that I like so much it did'nt really please as much as I thought it would. It had a nice amount of smokiness to it. Really obvious and pretty strong but not charred. But the oily consistency of the beer along with the huge saltiness made the beer less than I was hoping for. \\t\\tIt was still a beer that I'm glad I grabbed. They don't make many in the style anyways.\",\n",
       " 'user/profileName': 'cooch69',\n",
       " 'review/aroma': 3.5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parseDataFromFile(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)\n",
    "data = list(parseDataFromFile('beer_50000.json'))\n",
    "data[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_length = [len(d['review/text']) for d in data if 'user/gender' in d]\n",
    "def feature(datum):\n",
    "    feat = [[1, d] for d in datum]\n",
    "    return feat   \n",
    "feat = feature(review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = [d['user/gender'] for d in data if 'user/gender' in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(datum):\n",
    "    encoded = []\n",
    "    for i in range(len(datum)):\n",
    "        if datum[i] == 'Female':\n",
    "            encoded.append(1)\n",
    "        else:\n",
    "            encoded.append(0)\n",
    "    return encoded\n",
    "\n",
    "gender = encoder(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression classifier\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(feat, gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = mod.predict(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of true positive: 20095\n"
     ]
    }
   ],
   "source": [
    "def num_TP(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 0 and predict[i] == 0:\n",
    "                count = count + 1\n",
    "    return count\n",
    "number_true_positive = num_TP(gender, train_predictions)\n",
    "print('number of true positive:', number_true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of true negative: 0\n"
     ]
    }
   ],
   "source": [
    "def num_TN(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 1 and predict[i] == 1:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_true_negative = num_TN(gender, train_predictions)\n",
    "print('number of true negative:', number_true_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of false positive: 308\n"
     ]
    }
   ],
   "source": [
    "def num_FP(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 1 and predict[i] == 0:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_false_positive = num_FP(gender, train_predictions)\n",
    "print('number of false positive:', number_false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of false negative: 0\n"
     ]
    }
   ],
   "source": [
    "def num_FN(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 0 and predict[i] == 1:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_false_negative = num_FN(gender, train_predictions)\n",
    "print('number of false negative:', number_false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive rate:  1.0\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = number_false_positive / (number_false_positive + number_true_negative)\n",
    "print('false positive rate: ', false_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false negative rate:  0.0\n"
     ]
    }
   ],
   "source": [
    "false_negative_rate = number_false_negative / (number_false_negative + number_true_positive)\n",
    "print('false negative rate: ', false_negative_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced error rate:  0.5\n"
     ]
    }
   ],
   "source": [
    "print('Balanced error rate: ', 0.5*(false_positive_rate + false_negative_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Retrain the regressor using the class weight=’balanced’ option, and report the same error metrics as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of true positive: 8423\n",
      "number of true negative: 199\n",
      "number of false positive: 109\n",
      "number of false negative: 11672\n",
      "false positive rate:  0.3538961038961039\n",
      "false negative rate:  0.5808410052251803\n",
      "Balanced error rate:  0.4673685545606421\n"
     ]
    }
   ],
   "source": [
    "# Balanced model\n",
    "mod = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "mod.fit(feat, gender)\n",
    "train_predictions = mod.predict(feat)\n",
    "\n",
    "def num_TP(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 0 and predict[i] == 0:\n",
    "                count = count + 1\n",
    "    return count\n",
    "number_true_positive = num_TP(gender, train_predictions)\n",
    "print('number of true positive:', number_true_positive)\n",
    "\n",
    "def num_TN(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 1 and predict[i] == 1:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_true_negative = num_TN(gender, train_predictions)\n",
    "print('number of true negative:', number_true_negative)\n",
    "\n",
    "def num_FP(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 1 and predict[i] == 0:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_false_positive = num_FP(gender, train_predictions)\n",
    "print('number of false positive:', number_false_positive)\n",
    "\n",
    "def num_FN(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 0 and predict[i] == 1:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_false_negative = num_FN(gender, train_predictions)\n",
    "print('number of false negative:', number_false_negative)\n",
    "\n",
    "false_positive_rate = number_false_positive / (number_false_positive + number_true_negative)\n",
    "print('false positive rate: ', false_positive_rate)\n",
    "\n",
    "false_negative_rate = number_false_negative / (number_false_negative + number_true_positive)\n",
    "print('false negative rate: ', false_negative_rate)\n",
    "\n",
    "print('Balanced error rate: ', 0.5*(false_positive_rate + false_negative_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Improve your predictor (i.e., reduce the balanced error rate) by incorporating additional features from the data (e.g. beer styles, ratings, features from text, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = [d['review/overall'] for d in data if 'user/gender' in d]\n",
    "taste = [d['review/taste'] for d in data if 'user/gender' in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum1, datum2, datum3):\n",
    "    feat = [[1, d] for d in datum1]\n",
    "    for i in range(len(datum2)):\n",
    "        feat[i].append(datum2[i])\n",
    "    for i in range(len(datum3)):\n",
    "        feat[i].append(datum3[i])\n",
    "    return feat\n",
    "feat = feature(review_length, rate, taste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of true positive: 9808\n",
      "number of true negative: 187\n",
      "number of false positive: 121\n",
      "number of false negative: 10287\n",
      "false positive rate:  0.39285714285714285\n",
      "false negative rate:  0.5119183876586215\n",
      "Balanced error rate:  0.45238776525788216\n"
     ]
    }
   ],
   "source": [
    "# Balanced model\n",
    "mod = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "mod.fit(feat, gender)\n",
    "train_predictions = mod.predict(feat)\n",
    "\n",
    "def num_TP(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 0 and predict[i] == 0:\n",
    "                count = count + 1\n",
    "    return count\n",
    "number_true_positive = num_TP(gender, train_predictions)\n",
    "print('number of true positive:', number_true_positive)\n",
    "\n",
    "def num_TN(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 1 and predict[i] == 1:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_true_negative = num_TN(gender, train_predictions)\n",
    "print('number of true negative:', number_true_negative)\n",
    "\n",
    "def num_FP(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 1 and predict[i] == 0:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_false_positive = num_FP(gender, train_predictions)\n",
    "print('number of false positive:', number_false_positive)\n",
    "\n",
    "def num_FN(actual, predict):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 0 and predict[i] == 1:\n",
    "            count = count + 1\n",
    "    return count\n",
    "number_false_negative = num_FN(gender, train_predictions)\n",
    "print('number of false negative:', number_false_negative)\n",
    "\n",
    "false_positive_rate = number_false_positive / (number_false_positive + number_true_negative)\n",
    "print('false positive rate: ', false_positive_rate)\n",
    "\n",
    "false_negative_rate = number_false_negative / (number_false_negative + number_true_positive)\n",
    "print('false negative rate: ', false_negative_rate)\n",
    "\n",
    "print('Balanced error rate: ', 0.5*(false_positive_rate + false_negative_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
